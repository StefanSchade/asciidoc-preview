
// File: generate_output\api.sh Depth: 1

001 #!/bin/bash
002 
003 # Enable strict mode
004 set -euxo pipefail
005 IFS=$'\n\t'
006 
007 source "$SCRIPT_DIR/generate_output/_check_existence.sh"
008 source "$SCRIPT_DIR/generate_output/_find_adoc_dirs.sh"
009 source "$SCRIPT_DIR/generate_output/_generate_index.sh"
010 source "$SCRIPT_DIR/helper/sanitize_path.sh"
011 source "$SCRIPT_DIR/helper/absolute_path_to_relative_path.sh"
012 
013 refresh_output() {
014 
015   log "INFO" "inside refresh output"
016 
017   local relative_start_path=$1
018   local absolute_input_start_path="${INPUT_DIR}/${relative_start_path}"
019   local absolute_output_start_path="${OUTPUT_DIR}/${relative_start_path}"
020 
021   absolute_input_start_path=$(sanitize_path "$absolute_input_start_path")
022   absolute_output_start_path=$(sanitize_path "$absolute_output_start_path")
023 
024   log "INFO" "refreshing output $relative_start_path"
025   log "INFO" "absolute input start path $absolute_input_start_path"
026   log "INFO" "absolute output start path $absolute_output_start_path"
027 
028   if check_dir "$absolute_input_start_path"; then
029     log " INFO" "input dir is existing"
030   else
031     log "ERROR" "input dir is not existing"
032     exit 1
033   fi
034 
035 
036   if [ -d "$absolute_output_start_path" ]; then
037     log "INFO" "refreshing directory $absolute_output_start_path, cleaning html files that do not exist anymore"
038   find "$absolute_output_start_path" -name "*.html" -not -name "index.html" | while IFS= read -r html_file; do
039     # Determine the relative path of the HTML file in the input directory
040     relative_html_path=$(output_path_to_relative_path "$html_file")
041     input_file="${INPUT_DIR}/${relative_html_path%.html}.adoc"
042     # Check if the corresponding .adoc file still exists
043     if check_file "$input_file"; then
044         log "INFO" "$input_file exists - keep $html_file"
045     else
046         log "INFO" "$input_file does not exist anymore - removing $html_file"
047         rm -f "$html_file"
048     fi
049   done
050 
051 # index.html of the start dir excluded as it will be overwritten later - removing it early would disturb the live update
052     find_html_output=$(find "$absolute_output_start_path" -name "*.html" -not -name "index.html" -exec rm -f {} \; 2>&1)
053     if [[ $? -ne 0 ]]; then
054        log "ERROR" "no file found in ${absolute_output_start_path}, but that is not an error"
055     fi
056 
057     # remove later as this did just contribute to the debugging durign development
058     ls_output=$(ls -la "$absolute_output_start_path" 2>&1)
059     if [[ $? -eq 0 ]]; then
060        log "INFO" "directory content: $ls_output"
061     else
062        mog "ERROR" "Error listening directory content: $ls_output"
063     fi
064 
065     # find_dir_output=$(find "$absolute_output_start_path" -mindepth 1 -type d -not -path "*/\.*" -exec rm -rf {} \; 2>&1)
066     # results in an error as the parent directory might already have been removed before. therefore we switch to this form
067     find "$absolute_output_start_path" -mindepth 1 -type d -not -path "*/\.*" -print0 | tr '\0' '\n' | while IFS= read -d $'\n' outdir; do
068       if [ -n "$outdir" ]; then  # Add a check to ensure $dir is not empty
069          relative_output_path=$(output_path_to_relative_path "$outdir")
070          if [ -n "$relative_output_path" ]; then
071             indir="${INPUT_DIR}/$relative_output_path"
072          else
073             log "ERROR" "Could not determine relative output path for $outdir"
074             exit 1
075          fi
076             log "INFO" "checking if directory $indir should be removed"
077          if check_dir "$indir"; then
078             log "INFO" "directory $indir exists - skip removal of $outdir"
079          else
080             log "INFO" "directory $indir does not exist anymore - removing $outdir"
081             rm -rf "$outdir"
082          fi
083       fi
084     done
085   else
086     log "INFO" "output directory $absolute_output_start_path not existing, creating new directory"
087     mkdir_command_output=$(mkdir -p "$absolute_output_start_path" 2>&1)
088   fi
089 
090   # searching for directories containing *.adoc files below the current dir
091   local adoc_dir_array=()
092   find_adoc_dirs "$relative_start_path" adoc_dir_array
093   log "INFO" "Number of subdirectories found: ${#adoc_dir_array[@]}"
094   log "INFO" "directories that have to be processed: ${adoc_dir_array[*]}"
095 
096   log "INFO" "Start processing list of directories with input dir $INPUT_DIR and output dir $OUTPUT_DIR"
097   for subdir in "${adoc_dir_array[@]}"; do
098     log "INFO" "Processing dir $subdir "
099     mkdir -p "$OUTPUT_DIR/$subdir"
100     find "$INPUT_DIR/$subdir" -maxdepth 1 -name "*.adoc" | while read -r adoc_file; do
101       (cd "$INPUT_DIR/$subdir" && asciidoctor -a toc -D "$OUTPUT_DIR/$subdir" "$adoc_file" 2>&1)
102     done
103   done
104   generate_all_indexes "$relative_start_path"
105 }

// File: generate_output\_check_existence.sh Depth: 1

01 #!/bin/bash
02 
03 # Enable strict mode
04 set -euxo pipefail
05 IFS=$'\n\t'
06 
07 # Function to check if a file or directory exists
08 check_existence() {
09     local path=$1
10     local type=$2  # 'dir' or 'file'
11 
12     if [[ "$type" == "dir" && -d "$path" ]]; then
13         log "INFO" "Directory $path exists."
14         return 0  # Success
15     elif [[ "$type" == "file" && -f "$path" ]]; then
16         log "INFO" "File $path exists."
17         return 0  # Success
18     else
19         log "WARN" "$path does not exist."
20 
21         return 1  # Return non-zero to indicate the path is missing
22     fi
23 }
24 
25 # Check directory by calling check_existence
26 check_dir() {
27    check_existence "$1" "dir"
28    return $?  # Return the result of check_existence
29 }
30 
31 # Check file by calling check_existence
32 check_file() {
33    check_existence "$1" "file"
34    return $?  # Return the result of check_existence
35 }
36 

// File: generate_output\_find_adoc_dirs.sh Depth: 1

01 #!/bin/bash
02 
03 # Enable strict mode
04 set -euxo pipefail
05 IFS=$'\n\t'
06 
07 find_adoc_dirs() {
08   local relative_start_path="$1"
09   local absolute_input_start_path="${INPUT_DIR}/${relative_start_path}"
10   local -n adoc_dirs_ref=$2  # Use nameref to pass the array by reference
11 
12   log "INFO" "Searching for adocs in $absolute_input_start_path"
13   
14   # Always include the start dir even if there is no adoc at all
15   adoc_dirs_ref+=("$relative_start_path")
16 
17   # Capture the list of directories in a variable
18   local subdirs
19   subdirs=$(find "$absolute_input_start_path" -type d)
20 
21   # Iterate over the captured directories
22   while IFS= read -r subdir; do
23     echo "Checking subdir: $subdir" >&2
24     if [[ "$subdir" != "$absolute_input_start_path" && \
25           "$subdir" != "$absolute_input_start_path/.." && \
26           "$subdir" != "$absolute_input_start_path/." ]]; then
27       if find "$subdir" -maxdepth 1 -name "*.adoc" | read -r; then
28         relative_subdir="${subdir#$INPUT_DIR/}" # Remove base path
29         log "INFO" "Found .adoc in: $relative_subdir"
30         adoc_dirs_ref+=("$relative_subdir")
31       fi
32     fi
33   done <<< "$subdirs"
34 }

// File: generate_output\_generate_index.sh Depth: 1

01 #!/bin/bash
02 
03 # Enable strict mode
04 set -euxo pipefail
05 IFS=$'\n\t'
06 
07 list_all_output_dirs() {
08   find "$OUTPUT_DIR" -type d
09 }
10 
11 generate_index() {
12   local dir=$1
13   local index_file="${dir}/index.html"
14   echo "<html><body><h1>Generated Documentation</h1><ul>" > "$index_file"
15   
16   # Add links to subdirectory index files
17   for subdir in "$dir"/*; do
18     if [ -d "$subdir" ]; then
19       subdir_name=$(basename "$subdir")
20       echo "<li><strong><a href=\"$subdir_name/index.html\">$subdir_name</a></strong></li>" >> "$index_file"
21     fi
22   done
23 
24   # Add links to HTML files in the current directory
25   for file in "$dir"/*.html; do
26     if [ -f "$file" ]; then
27       filename=$(basename "$file")
28       if [ "$filename" != "index.html" ]; then
29         echo "<li><a href=\"$filename\">$filename</a></li>" >> "$index_file"
30       fi
31     fi
32   done
33 
34   echo "</ul></body></html>" >> "$index_file"
35 }
36 
37 generate_all_indexes() {
38   local relative_start_path="$1"
39   local dirs=()
40 
41   while IFS= read -r dir; do
42     dirs+=("$dir")
43   done < <(list_all_output_dirs $relative_start_path)
44 
45   for dir in "${dirs[@]}"; do
46     log "INFO" "Generating index for: $dir"
47     generate_index "$dir"
48   done
49 }

// File: helper\absolute_path_to_relative_path.sh Depth: 1

01 #!/bin/bash
02 
03 # Enable strict mode
04 set -euo pipefail
05 IFS=$'\n\t'
06 
07 absolute_path_to_relative_path() {
08   local absolute_path=$1
09   local base_path=${2%/}  # Remove trailing slash from base path if any
10 
11   # Ensure absolute path starts with base_path
12   if [[ $absolute_path == $base_path* ]]; then
13     echo "${absolute_path#$base_path/}"
14   else
15     echo "Error: The provided path does not start with the base path" >&2
16     return 1
17   fi
18 }
19 
20 # Delegate function for input path
21 input_path_to_relative_path() {
22   absolute_path_to_relative_path "$1" "$INPUT_DIR"
23 }
24 
25 # Delegate function for output path
26 output_path_to_relative_path() {
27   absolute_path_to_relative_path "$1" "$OUTPUT_DIR"
28 }
29 

// File: helper\cleanup.sh Depth: 1

01 #!/bin/bash
02 
03 # Enable strict mode
04 set -euxo pipefail
05 IFS=$'\n\t'
06 
07 cleanup() {
08     echo "Cleaning up..."
09     # Terminate watch and initialize WATCH_ID
10     if [ ! -z "${WATCH_PID:-}" ]; then
11         kill $WATCH_PID
12         wait $WATCH_PID 2>/dev/null
13     fi
14 
15     # Terminate the livereload process
16     if [ ! -z "$LIVERELOAD_PID" ]; then
17         kill $LIVERELOAD_PID
18         wait $LIVERELOAD_PID 2>/dev/null
19     fi
20 
21     exit 0
22 }

// File: helper\logger.sh Depth: 1

01 #!/bin/bash
02 
03 # Enable strict mode
04 set -euxo pipefail
05 IFS=$'\n\t'
06 
07 # Set default values if the variables are not provided
08 : "${LOG_FILE:=/var/log/default_log_file.log}"    # Default log file
09 : "${LOG_LEVEL:=INFO}"                            # Default log level
10 
11 MAX_SIZE=$((6 * 1024 * 1024))           # 6 MB
12 THRESHOLD_SIZE=$((5 * 1024 * 1024))     # 5 MB
13 
14 # Ensure the log file exists
15 touch "$LOG_FILE"
16 
17 # Log function
18 log() {
19     local level="${1//[[:space:]]/}"  # Remove any spaces from the log level argument
20     shift
21     local message="$*"
22     local timestamp=$(date +"%Y-%m-%d %H:%M:%S")
23 
24     # Define log levels
25     declare -A levels=( ["ERROR"]=0 ["WARN"]=1 ["INFO"]=2 ["DEBUG"]=3 )
26 
27     # Check if the log level allows logging this message
28     if (( ${levels[$level]} <= ${levels[$LOG_LEVEL]} )); then
29         echo "$timestamp [$level] $message" >> "$LOG_FILE"
30     fi
31 
32     # Check log file size and rotate if necessary
33     local file_size=$(stat -c%s "$LOG_FILE")
34     if (( file_size > MAX_SIZE )); then
35         echo "Log file size exceeded $MAX_SIZE bytes, rotating log file." >&2
36         local temp_file=$(mktemp)
37 
38         # Rotate the log file, keeping only the last THRESHOLD_SIZE bytes
39         tail -c $THRESHOLD_SIZE "$LOG_FILE" > "$temp_file" && mv "$temp_file" "$LOG_FILE"
40         echo "Log file trimmed to $THRESHOLD_SIZE bytes." >&2
41     fi
42 }

// File: helper\log_script_name.sh Depth: 1

01 #!/bin/bash
02 
03 # Enable strict mode
04 set -euxo pipefail
05 IFS=$'\n\t'
06 
07 source "$SCRIPT_DIR/helper/logger.sh"
08 
09 log_script_name() {
10 
11     local script_name=$(basename "$0")
12     local star_line=$(printf '%*s' "${#script_name}" | tr ' ' '*')
13 
14     log "INFO" "**""${star_line}""**"
15     log "INFO" "* ""${script_name}"" *"
16     log "INFO" "**""${star_line}""**"
17 }
18 

// File: helper\sanitize_path.sh Depth: 1

01 #! /bin/bash
02 
03 # Enable strict mode
04 set -euxo pipefail
05 IFS=$'\n\t'
06 
07 sanitize_path() {
08     local path=$1
09     # Remove trailing /. or /./
10     path="${path%.}"
11     path="${path%./}"
12     echo "$path"
13 }
14 
15 
16 

// File: livereloadx_server\api.sh Depth: 1

01 #!/bin/bash
02 
03 # Enable strict mode
04 set -euxo pipefail
05 IFS=$'\n\t'
06 
07 source "$SCRIPT_DIR/livereloadx_server/_check_server_status.sh"
08 
09 start_server() {
10   cd "$OUTPUT_DIR"
11   log "INFO" "Current working directory before starting livereloadx: $(pwd)"
12   log "INFO" "starting livereloadx server..."
13   livereloadx -s . -p 4000 --verbose &
14 
15   LIVERELOAD_PID=$!
16 
17   # Wait for livereloadx to start
18   sleep 5
19 
20   check_server_status
21 
22   # Adding a test request to see if the livereloadx server is responding correctly
23   curl -I http://localhost:4000
24 
25   # Exporting the PID to be used in cleanup
26   export LIVERELOAD_PID
27 }

// File: livereloadx_server\_check_server_status.sh Depth: 1

01 #!/bin/bash
02 
03 # Enable strict mode
04 set -euxo pipefail
05 IFS=$'\n\t'
06 
07 check_server_status() {
08   if ps -p $LIVERELOAD_PID > /dev/null; then
09     log "INFO" "livereloadx started successfully."
10   else
11     echo "Error: livereloadx failed to start."
12     exit 1
13   fi
14 }

// File: main.sh Depth: 0

01 #!/bin/bash
02 
03 # Enable strict mode
04 set -euxo pipefail
05 IFS=$'\n\t'
06 
07 # author: Stefan Schade
08 #
09 # description:
10 # starts the asciidoc-preview by performing these 3 tasks 
11 # 1. scan INPUT_DIR for asciidoc files (*.adoc), transform them into
12 #    html and replicate the input structure in OUTPUT_DIR
13 # 2. setting up a local web server that serves the html files to
14 #    localhost:4000. This server will refresh in case the html changes
15 # 3. watch the INPUT_DIR for changes to the asciidoc files or directories
16 #    and update the html.
17 
18 LOG_LEVEL=DEBUG
19 
20 # Get the directory of the currently executing script
21 SCRIPT_DIR=$(dirname "$(readlink -f "$0")")
22 
23 # Define the input apind output directories
24 OUTPUT_DIR=/workspace/output
25 INPUT_DIR=/workspace/input
26 LOG_DIR=/workspace/logs
27 LOG_FILE="$LOG_DIR/logfile.txt"
28 
29 mkdir -p "$OUTPUT_DIR"
30 mkdir -p "$LOG_DIR"
31 touch "$LOG_FILE"
32 
33 source "$SCRIPT_DIR/helper/log_script_name.sh" && log_script_name
34 source "$SCRIPT_DIR/helper/cleanup.sh"
35 source "$SCRIPT_DIR/generate_output/api.sh"
36 source "$SCRIPT_DIR/livereloadx_server/api.sh"
37 source "$SCRIPT_DIR/watch_changes/api.sh"
38 
39 log "INFO" "start logging"
40 log "INFO" "running script in directory $(pwd)"
41 log "INFO" "sourced scripts in $SCRIPT_DIR"
42 
43 trap 'cleanup' SIGINT SIGTERM
44 
45 main() {
46 
47   # initially process the whole input directory
48   # by using a path relative to the INPUT_DIR
49   log "INFO" "calling refresh outupt"
50   refresh_output "."
51   
52   start_server 
53 
54   watch_changes &
55   WATCH_PID=$!
56 
57   # Wait for background processes
58   wait $WATCH_PID
59   wait $LIVERELOAD_PID 
60 
61 }
62 
63 main
64 

// File: watch_changes\api.sh Depth: 1

001 #!/bin/bash
002 
003 # Enable strict mode
004 set -euxo pipefail
005 IFS=$'\n\t'
006 
007 # Source necessary helper scripts
008 source "$SCRIPT_DIR/watch_changes/_compare_snapshots.sh"
009 source "$SCRIPT_DIR/watch_changes/_generate_snapshot.sh"
010 source "$SCRIPT_DIR/helper/absolute_path_to_relative_path.sh"
011 
012 watch_changes() {
013   local old_snapshot=()
014   local new_snapshot=()
015 
016   generate_snapshot "$INPUT_DIR" old_snapshot
017 
018   while true; do
019     sleep 5
020     log "INFO" "watch_changes/api.sh: generate new snapshot"
021     generate_snapshot "$INPUT_DIR" new_snapshot
022 
023     log "INFO" "watch_changes/api.sh: compare snapshots"
024     local new_dirs=() deleted_dirs=() changed_dirs=()
025     local new_files=() deleted_files=() changed_files=()
026 
027     # Pass snapshots correctly to avoid circular reference
028     compare_snapshots old_snapshot new_snapshot new_dirs deleted_dirs changed_dirs new_files deleted_files changed_files
029 
030     # Output categorized changes to stdout
031     output_changes_to_stdout "${new_dirs[@]}" "Dir" "new"
032     output_changes_to_stdout "${deleted_dirs[@]}" "Dir" "deleted"
033     output_changes_to_stdout "${changed_dirs[@]}" "Dir" "changed"
034     output_changes_to_stdout "${new_files[@]}" "File" "new"
035     output_changes_to_stdout "${deleted_files[@]}" "File" "deleted"
036     output_changes_to_stdout "${changed_files[@]}" "File" "changed"
037 
038     # Handle changes
039     handle_dir_changes "${new_dirs[@]}" "new"
040     handle_dir_changes "${deleted_dirs[@]}" "deleted"
041     handle_dir_changes "${changed_dirs[@]}" "changed"
042 
043     handle_file_changes "${new_files[@]}" "new"
044     handle_file_changes "${deleted_files[@]}" "deleted"
045     handle_file_changes "${changed_files[@]}" "changed"
046 
047     old_snapshot=("${new_snapshot[@]}")
048   done
049 }
050 
051 # Function to output changes to stdout in a nice format
052 output_changes_to_stdout() {
053   local items=("$@")
054   
055   local type=${2:-"UnknownType"}
056   local change_type=${3:-"UnknownChangeType"}
057 
058   # Output each item
059   for item in "${items[@]}"; do
060     echo "$type $change_type: $item"
061   done
062 }
063 
064 
065 handle_dir_changes() {
066   local -n dirs=$1  # Pass array by reference
067   local type=$2
068   for dir in "${dirs[@]}"; do
069     relative_path=$(absolute_path_to_relative_path "$dir" "$INPUT_DIR")
070     log "INFO" "Handling $type directory: $dir"
071     # Handle actions based on type
072     if [ "$type" == "new" ]; then
073       refresh_output "$relative_path"
074     elif [ "$type" == "deleted" ]; then
075       local output_dir_path="${OUTPUT_DIR}/${relative_path}"
076       log "INFO" "Removing output directory: $output_dir_path"
077       rm -rf "$output_dir_path"
078     elif [ "$type" == "changed" ]; then
079       refresh_output "$relative_path"
080     fi
081   done
082 }
083 
084 handle_file_changes() {
085   local -n files=$1  # Pass array by reference
086   local type=$2
087   for file in "${files[@]}"; do
088     log "INFO" "handle_file_changes: $type $file"
089     local relative_path=$(absolute_path_to_relative_path "$file" "$INPUT_DIR")
090     local html_file="${OUTPUT_DIR}/${relative_path%.adoc}.html"
091     if [ "$type" == "new" ]; then
092       asciidoctor -a toc -D "$(dirname "$html_file")" "$file"
093     elif [ "$type" == "deleted" ]; then
094       log "INFO" "Removing output file: $html_file"
095       rm -f "$html_file"
096     elif [ "$type" == "changed" ]; then
097       asciidoctor -a toc -D "$(dirname "$html_file")" "$file"
098     fi
099   done
100 }
101 

// File: watch_changes\_compare_snapshots.sh Depth: 1

01 #!/bin/bash
02 
03 # Enable strict mode
04 set -euxo pipefail
05 IFS=$'\n\t'
06 
07 # Compare snapshots and categorize changes
08 compare_snapshots() {
09   local -n old_snapshot=$1
10   local -n new_snapshot=$2
11   local -n new_dirs_ref=$3
12   local -n deleted_dirs_ref=$4
13   local -n changed_dirs_ref=$5
14   local -n new_files_ref=$6
15   local -n deleted_files_ref=$7
16   local -n changed_files_ref=$8
17 
18   local -A new_dirs_unique=()
19   local -A deleted_dirs_unique=()
20   local -A changed_dirs_unique=()
21   local -A new_files_unique=()
22   local -A deleted_files_unique=()
23   local -A changed_files_unique=()
24 
25   # Rename snapshot lists to old/new for better clarity
26   local old_dirs_snapshot=$(printf "%s\n" "${old_snapshot[@]}" | grep '^D' | sort)
27   local new_dirs_snapshot=$(printf "%s\n" "${new_snapshot[@]}" | grep '^D' | sort)
28   local old_files_snapshot=$(printf "%s\n" "${old_snapshot[@]}" | grep '^F' | sort)
29   local new_files_snapshot=$(printf "%s\n" "${new_snapshot[@]}" | grep '^F' | sort)
30 
31   # Handle directories
32   handle_changes "directory" "$old_dirs_snapshot" "$new_dirs_snapshot" new_dirs_unique deleted_dirs_unique changed_dirs_unique
33   # Handle files
34   handle_changes "file" "$old_files_snapshot" "$new_files_snapshot" new_files_unique deleted_files_unique changed_files_unique
35 
36   # Transfer to reference variables for final output
37   new_dirs_ref=("${!new_dirs_unique[@]}")
38   deleted_dirs_ref=("${!deleted_dirs_unique[@]}")
39   changed_dirs_ref=("${!changed_dirs_unique[@]}")
40   new_files_ref=("${!new_files_unique[@]}")
41   deleted_files_ref=("${!deleted_files_unique[@]}")
42   changed_files_ref=("${!changed_files_unique[@]}")
43 }
44 
45 # Generalized change handler
46 handle_changes() {
47   local type=$1
48   local old_snapshot_list=$2
49   local new_snapshot_list=$3
50   local -n new_ref=$4
51   local -n deleted_ref=$5
52   local -n changed_ref=$6
53 
54   # Check for removed entries (in old but not in new)
55   comm -23 <(echo "$old_snapshot_list") <(echo "$new_snapshot_list") | while read -r line; do
56     log "DEBUG" "Found removed $type: $line"
57     deleted_ref["$(echo "$line" | cut -d' ' -f3-)"]=1
58   done
59 
60   # Check for added entries (in new but not in old)
61   comm -13 <(echo "$old_snapshot_list") <(echo "$new_snapshot_list") | while read -r line; do
62     log "DEBUG" "Found added $type: $line"
63     new_ref["$(echo "$line" | cut -d' ' -f3-)"]=1
64   done
65 
66   # Detect changes based on timestamp differences (when present in both new and old)
67   while read -r old_line; do
68     local old_timestamp=$(echo "$old_line" | cut -d' ' -f2)
69     local entry=$(echo "$old_line" | cut -d' ' -f3-)
70     local new_line=$(echo "$new_snapshot_list" | grep " $entry$")
71     if [[ -n "$new_line" ]]; then
72       local new_timestamp=$(echo "$new_line" | cut -d' ' -f2)
73       if [[ "$old_timestamp" != "$new_timestamp" ]]; then
74         log "DEBUG" "Found timestamp change in $type: $entry"
75         changed_ref["$entry"]=1
76         # Remove from both new and deleted if it was marked as both (meaning it changed)
77         unset new_ref["$entry"]
78         unset deleted_ref["$entry"]
79       fi
80     fi
81   done <<< "$old_snapshot_list"
82 }
83 

// File: watch_changes\_generate_snapshot.sh Depth: 1

01 #!/bin/bash
02 
03 # Enable strict mode
04 set -euxo pipefail
05 # IFS=$'\n\t'
06 
07 generate_snapshot() {
08   local dir=$1
09   local -n snapshot=$2
10   snapshot=()
11 
12   # Loop through each file or directory in the specified path
13   while IFS= read -r -d '' entry; do
14     if [ -d "$entry" ]; then
15       snapshot+=("D $(stat --format='%Y' "$entry") $entry")
16     elif [ -f "$entry" ]; then
17       # File snapshot with 'F' prefix
18       snapshot+=("F $(stat --format='%Y' "$entry") $entry")
19     else
20       echo "Warning: '$entry' does not exist or is neither a file nor a directory, skipping..." >&2
21     fi
22     done < <(find "$dir" -type f \( -name '*.adoc' -o -name '*.asciidoc' \) \
23                          -exec dirname {} \; | sort -u | \
24                          xargs -I {} find {} \( -type d -o -type f \
25                          \( -name '*.adoc' -o -name '*.asciidoc' \) \) -print0)
26   
27     log "DEBUG" "Snapshot for $dir: ${snapshot[*]}"
28 }
29 
